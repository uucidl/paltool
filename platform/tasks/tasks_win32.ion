import containers

import platform.win32

struct WorkerThread
{
  lock: win32.SRWLOCK;
  idx: int;
  bitmask: int;
  queue: ThreadWorkQueue;
}

struct NativeThreads
{
  num_threads: usize;
  thread_handles: win32.HANDLE*;
  thread_states : WorkerThread*;
}

var registry_lock : win32.SRWLOCK;
var native_threads : NativeThreads;

// @todo @ion add/show which argument is invalid:
// Invalid type in function call argument

// @todo CreateThread vs _beginthreadex .. what's the deal?

func platform_tasks_init()
{
  win32.AcquireSRWLockExclusive(&registry_lock);
  registry_init();
  num_cpus := _get_num_logical_cpus();
  containers.buf_alloc_at(&native_threads.thread_states, sizeof(native_threads.thread_states[0]), num_cpus - 1);
  for (i:=0; i<num_cpus; i++) {
    #assert(i < 8*sizeof(native_threads.thread_states[i].bitmask));
    native_threads.thread_states[i].idx = i;
    native_threads.thread_states[i].bitmask = 1<<i;
    handle := win32.CreateThread(NULL, 0, task_core_worker, &native_threads.thread_states[i], win32.CREATE_SUSPENDED, NULL);
    if (!handle) {
      // @todo @error_handling
      err := win32.GetLastError();
      #assert(err == 0);
    }
    containers.buf_push(&native_threads.thread_handles, &handle, sizeof(handle));
  }
  native_threads.num_threads = containers.buf_len(native_threads.thread_handles);
  #assert(containers.buf_len(native_threads.thread_states) == native_threads.num_threads);
  if (native_threads.num_threads == 0) {
    // @todo @error_handling tell users we switched to synchronous execution
    #assert(false);
  }
  for (i:=0; i<native_threads.num_threads; i++) {
    win32.ResumeThread(native_threads.thread_handles[i]);
  }
  win32.ReleaseSRWLockExclusive(&registry_lock);
}

func platform_tasks_deinit()
{
  win32.AcquireSRWLockExclusive(&registry_lock);
  // Shutdown all native threads:
  for (i:=0; i<native_threads.num_threads; i++) {
    handle := native_threads.thread_handles[i];
    success := win32.TerminateThread(handle, '?');
    if (!success) {
      // @todo @error_handling
      err := win32.GetLastError();
      #assert(false);
    }
    success = win32.CloseHandle(handle);
    if (!success) {
      // @todo @error_handling
      err := win32.GetLastError();
      #assert(false);
    }
  }
  buf_free(native_threads.thread_handles);
  native_threads = {};
  registry_deinit();
  win32.ReleaseSRWLockExclusive(&registry_lock);
}

func platform_create_task(fn : TaskFunc, data : void*) : Task
{
  win32.AcquireSRWLockExclusive(&registry_lock);
  result := unstarted_create(&unstarted_tasks, {data=data, fn=fn});
  win32.ReleaseSRWLockExclusive(&registry_lock);
  return result;
}


func platform_task_depends_on(task : Task, dependency : Task)
{
  win32.AcquireSRWLockExclusive(&registry_lock);
  unstarted_depends_on(&unstarted_tasks, task, dependency);
  win32.ReleaseSRWLockExclusive(&registry_lock);
}

// Schedule a task to run as soon as possible
func platform_start_task(task : Task)
{
  win32.AcquireSRWLockExclusive(&registry_lock);
  task_being_blocked := unstarted_tasks.buf[unpack_idx_from_id(task)].task_being_blocked;
  content := unstarted_discard(&unstarted_tasks, task);
  #assert(!unstarted_blocker_exists_for(&unstarted_tasks, task));
  win32.ReleaseSRWLockExclusive(&registry_lock);

  if (native_threads.num_threads == 0) {
    content.fn(content.data);
    #assert(false); // implement running the task being blocked
    return;
  }

  thread := &native_threads.thread_states[
    pick_thread_idx(content, native_threads.num_threads)
  ];

  win32.AcquireSRWLockExclusive(&thread.lock);
  pending_tasks_add(&thread.queue.pending_tasks, task, task_being_blocked, content);
  blocked_tasks_update(&thread.queue, thread.bitmask, thread.queue.pending_tasks.len, thread.queue.pending_tasks.blocks);
  for (other_thread_idx := (thread.idx + 1) % native_threads.num_threads; other_thread_idx != thread.idx; other_thread_idx = (other_thread_idx + 1) % native_threads.num_threads) {
    other_thread := &native_threads.thread_states[other_thread_idx];
    win32.AcquireSRWLockShared(&other_thread.lock);
    blocked_tasks_update(&thread.queue, other_thread.bitmask, other_thread.queue.pending_tasks.len, other_thread.queue.pending_tasks.blocks);
    win32.ReleaseSRWLockShared(&other_thread.lock);
  }
  win32.ReleaseSRWLockExclusive(&thread.lock);
}

func platform_run_task(task: Task)
{
  // @todo this is a waitable task: pull it from unstarted, allocate condition var + lock for waiting for it.
  // then block here until the condition variable has signaled.
  #assert(false); // @todo: implement me (see above)
}

func _get_num_logical_cpus() : int
{
  system_info : win32.SYSTEM_INFO;
  win32.GetSystemInfo(&system_info);
  return system_info.dwNumberOfProcessors;
}

func task_core_worker(lpParameter: void*) : uint32
{
  thread: WorkerThread* = lpParameter;
  while (true) {
    task: Task;
    content: TaskContent;
    win32.AcquireSRWLockExclusive(&thread.lock);
    {
      blocked_tasks_update(&thread.queue, thread.bitmask, thread.queue.pending_tasks.len, thread.queue.pending_tasks.blocks);
      ready_idx := thread_work_queue_find_index_first_ready(&thread.queue, 0);
      if (ready_idx < thread.queue.pending_tasks.len) {
        thread.queue.pending_tasks.executing[ready_idx] = true;
        task = thread.queue.pending_tasks.tasks[ready_idx];
        content = thread.queue.pending_tasks.contents[ready_idx];
      }
    }
    // @todo for any task not blocked anymore by ourselves, check if it is still blocked by other threads
    win32.ReleaseSRWLockExclusive(&thread.lock);

    if (content.fn) {
      content.fn(content.data);
      win32.AcquireSRWLockExclusive(&thread.lock);
      {
        ready_idx := thread.queue.pending_tasks.len;
        for (i:=0; i<thread.queue.pending_tasks.len; i++) {
          if (Task_compare(thread.queue.pending_tasks.tasks[i], task) == 0) {
            ready_idx = i;
            break;
          }
        }
        #assert(thread.queue.pending_tasks.executing[ready_idx]);
        pending_tasks_remove(&thread.queue.pending_tasks, ready_idx); 
      }
      win32.ReleaseSRWLockExclusive(&thread.lock);
    } else {
      // verify if maybe one of our tasks being blocked by other threads is free now?

      // try stealing a task from other threads:
      next_idx := (thread.idx + 1) % native_threads.num_threads;
      got_one := false;
      for (; !got_one && next_idx != thread.idx; next_idx = (next_idx + 1) % native_threads.num_threads) {
        other_thread := &native_threads.thread_states[next_idx];
        if (!win32.TryAcquireSRWLockExclusive(&other_thread.lock)) { continue; }
        ready_idx := thread_work_queue_find_index_first_ready(&other_thread.queue, 0);
        
        // refresh which ones of threads' tasks are blocked by other thread's tasks
        blocked_tasks_update(&thread.queue, other_thread.bitmask, other_thread.queue.pending_tasks.len, other_thread.queue.pending_tasks.blocks);

        if (ready_idx < other_thread.queue.pending_tasks.len) {
          win32.AcquireSRWLockExclusive(&thread.lock);
          pending_tasks_add(&thread.queue.pending_tasks, other_thread.queue.pending_tasks.tasks[ready_idx], other_thread.queue.pending_tasks.blocks[ready_idx], other_thread.queue.pending_tasks.contents[ready_idx]);
          pending_tasks_remove(&other_thread.queue.pending_tasks, ready_idx);
          win32.ReleaseSRWLockExclusive(&thread.lock);
          got_one = true;
        }
        win32.ReleaseSRWLockExclusive(&other_thread.lock);
      }
      if (!got_one) {
        win32.SleepEx(1000, false); // @todo replace with condition variable waiting for new tasks in our queue
      }
    }
  }
  return '?';
}

func pick_thread_idx(content : TaskContent, num_threads: usize) : usize
{
  hash := hash_init();
  hash = hash_mix_bytes(hash, (:uint8*)&content.data, sizeof(content.data));
  hash = hash_mix_bytes(hash, (:uint8*)&content.fn, sizeof(content.fn));
  thread_idx := hash % native_threads.num_threads;
  #assert(thread_idx >= 0 && thread_idx < num_threads);
  return thread_idx;
}

/*

Context
- user wants to maximize CPU core utilization,
- user has many independent chunks of computations,
- tasks are >=1ms worth of CPU processing,
- tasks don't do general I/O, only CPU + Mem

Value
- duration(task_processing(tasks, core_count)) < duration(serial_processing(tasks))
  when core_count > 1
- core_count_1 > core_count_0 => duration(task_processing(tasks, core_count_1)) 
  < duration(task_processing(tasks, core_count_0))

Cost  
- overhead = duration(task_processing(tasks, core_count)) - duration(serial_procesing(tasks))/core_count

*/
