import .dispatch

import datum {...}

import libc
import platform.bsd
import std

var submission_queue : dispatch.Queue;
var main_queue : dispatch.Queue;
var groups : GroupRegistry;

struct GroupRegistry
{
   group_per_task: dispatch.Group*;
   len: usize;
}

func platform_tasks_init() {
  registry_init();
  submission_queue = dispatch.queue_create("tasks_submit", NULL);
  #assert(submission_queue);
  main_queue = dispatch.queue_create("tasks_main", NULL);
  dispatch.set_target_queue({_dq=main_queue}, dispatch.get_global_queue(dispatch.QUEUE_PRIORITY_DEFAULT, 0));
}

func platform_tasks_deinit() {
  #assert(submission_queue);
  dispatch.release({_dq=submission_queue});
  dispatch.release({_dq=main_queue});
  for (i:=0; i<std.alen(groups.group_per_task); i++) {
    g := groups.group_per_task[i];
    if (g) {
      dispatch.release({_dg = g});
    }
  }
  std.afree(groups.group_per_task);
  submission_queue = NULL;
  main_queue = NULL;
  registry_deinit();
}

struct NewTaskData
{
  data : void*;
  fn : TaskFunc;
  task : Task;
}

@type_erased("{opaque_data: NewTaskData}")
func _add_task_submission_task(opaque_data : void*) {
  data : NewTaskData* = opaque_data;
  data.task = unstarted_create(&unstarted_tasks, {data=data.data, fn=data.fn});
}

struct DependsOnData
{
  task: Task;
  dependency: Task;
}

@type_erased("{opaque_data: DependsOnData}")
func _depends_on_submission_task(opaque_data: void*) {
  data: DependsOnData* = opaque_data;
  unstarted_depends_on(&unstarted_tasks, data.task, data.dependency);

  group: dispatch.Group*;
  task_idx := unpack_idx_from_id(data.task);
  if (task_idx < std.alen(groups.group_per_task)) {
    std.afit(groups.group_per_task, task_idx + 1);
    std.asetlen(groups.group_per_task, task_idx + 1);
  }
  group = &groups.group_per_task[task_idx];
  groups.len = std.alen(groups.group_per_task);
  if (!*group) {
    *group = dispatch.group_create();
    #assert(*group);
  }
}

// Create a new task and returns its handle
func platform_create_task(fn : TaskFunc, data : void*) : Task {
  #assert(submission_queue); // you forgot to call tasks_init
  submission_data := NewTaskData {
    data = data,
    fn = fn,
  };
  dispatch.dispatch_sync(submission_queue, &submission_data, _add_task_submission_task);
  return submission_data.task;
}

// Mark a dependency between two tasks
func platform_task_depends_on(task : Task, dependency : Task) {
  depends_on_data := DependsOnData {
    task = task,
    dependency = dependency,
  };
  dispatch.dispatch_sync(submission_queue, &depends_on_data, _depends_on_submission_task);
}

struct DispatchTaskData
{
  content: TaskContent;
  group: dispatch.Group;
}

@type_erased("{opaque_data: DispatchTaskData*}")
func run_task_task(opaque_data : void*) {
  data : DispatchTaskData* = opaque_data;
  data.content.fn(data.content.data);
  if (data.group) {
    dispatch.group_leave(data.group);
    dispatch.release({ _dg = data.group });
  }
  libc.free(data);
}

func _make_dispatch_task_data(unstarted : UnstartedTask) : DispatchTaskData* {
  blocked_task := unstarted.task_being_blocked;
  group: dispatch.Group;
  if (blocked_task.value) {
    group = groups.group_per_task[unpack_idx_from_id(blocked_task)];
    #assert(group);
  }
  result: DispatchTaskData*;
  result = libc.calloc(1, sizeof(*result));
  result.content = unstarted.content;
  result.group = group;
  return result;
}


// Schedule a task to run as soon as possible
func platform_start_task(task : Task) {
  // @todo all dependencies should have been started already
  // this is also consistent with this caveat from the dispatch Man page:
  //   In order to ensure deterministic behavior, it is recommended to call
  //   dispatch_group_wait() only once all blocks have been submitted to the
  //   group. If it is later determined that new blocks should be run, it is
  //   recommended not to reuse an already-running group, but to create a new
  //   group.
  // 
  // @todo: thread safety with submission
  idx := unpack_idx_from_id(task);
  blocked_task := unstarted_tasks.buf[idx].task_being_blocked;

  dispatch_task_data := _make_dispatch_task_data(unstarted_tasks.buf[idx]);
  unstarted_discard(&unstarted_tasks, task);

  if (dispatch_task_data.group) {
    dispatch.retain({_dg = dispatch_task_data.group });
    dispatch.group_enter(dispatch_task_data.group);
  }

  wait_on_group: dispatch.Group = idx<groups.len? groups.group_per_task[idx] : NULL;
  if (wait_on_group) {
    dispatch.dispatch_group_notify(wait_on_group, main_queue, dispatch_task_data, run_task_task);
  } else {
    dispatch.dispatch_async(main_queue, dispatch_task_data, run_task_task);
  }
}

func platform_run_task_and_wait(task: Task) {
  // @todo: thread safety with submission
  idx := unpack_idx_from_id(task);
  wait_on_group: dispatch.Group = idx<groups.len? groups.group_per_task[idx] : NULL;
  if (wait_on_group) {
    err := dispatch.group_wait(wait_on_group, dispatch.TIME_FOREVER);
    #assert(err == 0); // according to manual, must happen with TIME_FOREVER
  }
  dispatch_task_data := _make_dispatch_task_data(unstarted_tasks.buf[idx]);
  unstarted_discard(&unstarted_tasks, task);

  if (dispatch_task_data.group) {
    dispatch.retain({_dg = dispatch_task_data.group });
    dispatch.group_enter(dispatch_task_data.group);
  }
  dispatch.dispatch_sync(main_queue, dispatch_task_data, run_task_task);
}

func _get_num_logical_cpus() : int
{
  count : int;
  count_size := (:bsd.size_t) sizeof(count);
  rc := bsd.sysctlbyname("hw.activecpu", &count, &count_size, NULL, 0);
  if (rc == 0) { return count; }
  rc = bsd.sysctlbyname("hw.logicalcpu", &count, &count_size, NULL, 0);
  if (rc == 0) { return count; }
  rc = bsd.sysctlbyname("hw.ncpu", &count, &count_size, NULL, 0);
  if (rc == 0) { return count; }
  return 0;
}