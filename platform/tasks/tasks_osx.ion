import .dispatch

import datum {...}

import libc
import platform.bsd

var submission_queue : dispatch.Queue;
var main_queue : dispatch.Queue;
var groups : GroupRegistry;

struct GroupRegistry
{
   group_per_task: dispatch.Group*;
   len: usize;
}

func platform_tasks_init() {
  registry_init();
  submission_queue = dispatch.queue_create("tasks_submit", NULL);
  #assert(submission_queue);
  main_queue = dispatch.queue_create("tasks_main", NULL);
  dispatch.set_target_queue({_dq=main_queue}, dispatch.get_global_queue(dispatch.QUEUE_PRIORITY_DEFAULT, 0));
}

func platform_tasks_deinit() {
  #assert(submission_queue);
  // do on submission queu
  for (i:=0; i<groups.len; i++) {
  }
  dispatch.release({_dq=submission_queue});
  dispatch.release({_dq=main_queue});
  submission_queue = NULL;
  registry_deinit();
}

struct NewTaskData
{
  data : void*;
  fn : TaskFunc;
  task : Task;
}

@type_erased("{opaque_data: NewTaskData}")
func _add_task_submission_task(opaque_data : void*) {
  data : NewTaskData* = opaque_data;
  data.task = unstarted_create(&unstarted_tasks, {data=data.data, fn=data.fn});
}

struct DependsOnData
{
  task: Task;
  dependency: Task;
}

@type_erased("{opaque_data: DependsOnData}")
func _depends_on_submission_task(opaque_data: void*) {
  data: DependsOnData* = opaque_data;
  unstarted_depends_on(&unstarted_tasks, data.task, data.dependency);

  group: dispatch.Group*;
  group = buf_alloc_at(&groups.group_per_task, sizeof(*group), unpack_idx_from_id(data.task));
  if (!*group) {
    *group = dispatch.group_create();
    #assert(*group);
  }
}

// Create a new task and returns its handle
func platform_create_task(fn : TaskFunc, data : void*) : Task {
  #assert(submission_queue); // you forgot to call tasks_init
  submission_data := NewTaskData {
    data = data,
    fn = fn,
  };
  dispatch.dispatch_sync(submission_queue, &submission_data, _add_task_submission_task);
  return submission_data.task;
}

// Mark a dependency between two tasks
func platform_task_depends_on(task : Task, dependency : Task) {
  depends_on_data := DependsOnData {
    task = task,
    dependency = dependency,
  };
  dispatch.dispatch_sync(submission_queue, &depends_on_data, _depends_on_submission_task);
}

func run_task_task(opaque_data : void*) {
  data : TaskContent* = opaque_data;
  data.fn(data.data);
  data.fn = NULL; // mark task has completed.
  libc.free(data);
}

// Schedule a task to run as soon as possible
func platform_start_task(task : Task) {
  // @todo all dependencies should have been started already
  // this is also consistent with this caveat from the dispatch Man page:
  //   In order to ensure deterministic behavior, it is recommended to call
  //   dispatch_group_wait() only once all blocks have been submitted to the
  //   group. If it is later determined that new blocks should be run, it is
  //   recommended not to reuse an already-running group, but to create a new
  //   group.
  // 
  // @todo: thread safety with submission
  idx := unpack_idx_from_id(task);
  blocked_task := unstarted_tasks.buf[idx].task_being_blocked;
  group: dispatch.Group;
  if (blocked_task.value) {
    group = groups.group_per_task[unpack_idx_from_id(blocked_task)];
    #assert(group);
  }
  wait_on_group: dispatch.Group = groups.group_per_task[idx];
  
  content := unstarted_discard(&unstarted_tasks, task);
  content_ptr := &content;
  content_ptr = libc.calloc(1, sizeof(content_ptr[0]));
  *content_ptr = content;

  // @todo what if you have a task that waits for predecessors
  // and also has other tasks waiting for it?
  // Is it all easier if expressed in terms of group enter/leave?
  if (group) {
    dispatch.dispatch_group_async(group, main_queue, content_ptr, run_task_task);
  } else if (wait_on_group) {
    dispatch.dispatch_group_notify(wait_on_group, main_queue, content_ptr, run_task_task);
  } else {
    dispatch.dispatch_async(main_queue, content_ptr, run_task_task);
  }
}

func platform_run_task(task: Task) {
  // @todo: thread safety with submission
  idx := unpack_idx_from_id(task);
  wait_on_group: dispatch.Group = groups.group_per_task[idx];
  if (wait_on_group) {
    err := dispatch.group_wait(wait_on_group, dispatch.TIME_FOREVER);
    #assert(err == 0); // according to manual, must happen with TIME_FOREVER
  }
  content := unstarted_discard(&unstarted_tasks, task);
  content_ptr := &content;
  content_ptr = libc.calloc(1, sizeof(content_ptr[0]));
  *content_ptr = content;
  dispatch.dispatch_sync(main_queue, content_ptr, run_task_task);
}

func _get_num_logical_cpus() : int
{
  count : int;
  count_size := (:bsd.size_t) sizeof(count);
  rc := bsd.sysctlbyname("hw.activecpu", &count, &count_size, NULL, 0);
  if (rc == 0) { return count; }
  rc = bsd.sysctlbyname("hw.logicalcpu", &count, &count_size, NULL, 0);
  if (rc == 0) { return count; }
  rc = bsd.sysctlbyname("hw.ncpu", &count, &count_size, NULL, 0);
  if (rc == 0) { return count; }
  return 0;
}